{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":64148,"databundleVersionId":7669720,"sourceType":"competition"},{"sourceId":7672449,"sourceType":"datasetVersion","datasetId":4475281},{"sourceId":7705679,"sourceType":"datasetVersion","datasetId":4498747},{"sourceId":11371,"sourceType":"modelInstanceVersion","modelInstanceId":5171},{"sourceId":11216,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":5305}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# starter code already provided by Kaggle\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-01T03:37:08.960868Z","iopub.execute_input":"2024-03-01T03:37:08.961407Z","iopub.status.idle":"2024-03-01T03:37:09.385527Z","shell.execute_reply.started":"2024-03-01T03:37:08.961373Z","shell.execute_reply":"2024-03-01T03:37:09.384360Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/data-science-interview-q-and-a-treasury/dataset.csv\n/kaggle/input/gemma/keras/gemma_2b_en/2/config.json\n/kaggle/input/gemma/keras/gemma_2b_en/2/tokenizer.json\n/kaggle/input/gemma/keras/gemma_2b_en/2/metadata.json\n/kaggle/input/gemma/keras/gemma_2b_en/2/model.weights.h5\n/kaggle/input/gemma/keras/gemma_2b_en/2/assets/tokenizer/vocabulary.spm\n/kaggle/input/gemma/pytorch/2b/1/config.json\n/kaggle/input/gemma/pytorch/2b/1/gemma-2b.ckpt\n/kaggle/input/gemma/pytorch/2b/1/tokenizer.model\n/kaggle/input/data-assistants-with-gemma/submission_categories.txt\n/kaggle/input/data-assistants-with-gemma/submission_instructions.txt\n/kaggle/input/parquetfile-python-25k/0000.parquet\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport re\n\n\n# Install Keras 3 last. \n!pip install -q -U keras-nlp\n!pip install -q -U keras>=3\n\nimport os\n\nos.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n# Avoid memory fragmentation on JAX backend.\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"\n\nimport keras\nimport keras_nlp","metadata":{"execution":{"iopub.status.busy":"2024-03-01T03:37:11.722220Z","iopub.execute_input":"2024-03-01T03:37:11.723111Z","iopub.status.idle":"2024-03-01T03:37:56.515550Z","shell.execute_reply.started":"2024-03-01T03:37:11.723080Z","shell.execute_reply":"2024-03-01T03:37:56.514371Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\ntensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2024-03-01 03:37:46.858858: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-01 03:37:46.858960: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-01 03:37:47.006391: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"#Creating the model using the from_preset method\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")","metadata":{"execution":{"iopub.status.busy":"2024-03-01T03:37:58.595344Z","iopub.execute_input":"2024-03-01T03:37:58.596389Z","iopub.status.idle":"2024-03-01T03:38:54.703070Z","shell.execute_reply.started":"2024-03-01T03:37:58.596356Z","shell.execute_reply":"2024-03-01T03:38:54.702181Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nnormalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"}]},{"cell_type":"code","source":"gemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T03:38:59.671024Z","iopub.execute_input":"2024-03-01T03:38:59.671776Z","iopub.status.idle":"2024-03-01T03:38:59.706014Z","shell.execute_reply.started":"2024-03-01T03:38:59.671746Z","shell.execute_reply":"2024-03-01T03:38:59.705050Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/data-science-interview-q-and-a-treasury/dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-01T03:39:02.757687Z","iopub.execute_input":"2024-03-01T03:39:02.758108Z","iopub.status.idle":"2024-03-01T03:39:02.777618Z","shell.execute_reply.started":"2024-03-01T03:39:02.758075Z","shell.execute_reply":"2024-03-01T03:39:02.776386Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T03:39:05.344437Z","iopub.execute_input":"2024-03-01T03:39:05.344817Z","iopub.status.idle":"2024-03-01T03:39:05.360946Z","shell.execute_reply.started":"2024-03-01T03:39:05.344788Z","shell.execute_reply":"2024-03-01T03:39:05.359569Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                            question  \\\n0             What is supervised machine learning? 👶   \n1  What is regression? Which models can you use t...   \n2    What is linear regression? When do we use it? 👶   \n3  What are the main assumptions of linear regres...   \n4  What’s the normal distribution? Why do we care...   \n\n                                              answer  \n0  Supervised learning is a type of machine learn...  \n1  Regression is a part of supervised ML. Regress...  \n2  Linear regression is a model that assumes a li...  \n3  There are several assumptions of linear regres...  \n4  The normal distribution is a continuous probab...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is supervised machine learning? 👶</td>\n      <td>Supervised learning is a type of machine learn...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is regression? Which models can you use t...</td>\n      <td>Regression is a part of supervised ML. Regress...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What is linear regression? When do we use it? 👶</td>\n      <td>Linear regression is a model that assumes a li...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What are the main assumptions of linear regres...</td>\n      <td>There are several assumptions of linear regres...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What’s the normal distribution? Why do we care...</td>\n      <td>The normal distribution is a continuous probab...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Preparing the dataset for fine-tuning\ndataset = []\n    \nfor index, row in data.iterrows():\n    question, answer = row['question'], row['answer']\n    template = (f\"Question:\\n{question}\\n\\nAnswer:\\n{answer}\")\n    dataset.append(template)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T03:39:07.919920Z","iopub.execute_input":"2024-03-01T03:39:07.920615Z","iopub.status.idle":"2024-03-01T03:39:07.939820Z","shell.execute_reply.started":"2024-03-01T03:39:07.920587Z","shell.execute_reply":"2024-03-01T03:39:07.938788Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Enabling LoRA for the model and setting the LoRA rank to 64\n# we could also do a smaller rank like 4 or 16 for computational efficiency\ngemma_lm.backbone.enable_lora(rank=64)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T03:39:10.833063Z","iopub.execute_input":"2024-03-01T03:39:10.833463Z","iopub.status.idle":"2024-03-01T03:39:11.278010Z","shell.execute_reply.started":"2024-03-01T03:39:10.833433Z","shell.execute_reply":"2024-03-01T03:39:11.276962Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Limiting the input sequence length to 512 (to control memory usage).\ngemma_lm.preprocessor.sequence_length = 512\n# Use of AdamW - a common optimizer for transformer models\noptimizer = keras.optimizers.AdamW(\n    learning_rate=5e-5,\n    weight_decay=0.01,\n)\n# Excluding layernorm and bias terms from decay.\noptimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()])\n\ngemma_lm.fit(dataset, epochs=15, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T03:39:14.396789Z","iopub.execute_input":"2024-03-01T03:39:14.397183Z","iopub.status.idle":"2024-03-01T04:10:29.217884Z","shell.execute_reply.started":"2024-03-01T03:39:14.397154Z","shell.execute_reply":"2024-03-01T04:10:29.216842Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/15\n\u001b[1m166/166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 736ms/step - loss: 0.4805 - sparse_categorical_accuracy: 0.5616\nEpoch 2/15\n\u001b[1m166/166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 733ms/step - loss: 0.4116 - sparse_categorical_accuracy: 0.5932\nEpoch 3/15\n\u001b[1m166/166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 734ms/step - loss: 0.3933 - sparse_categorical_accuracy: 0.6029\nEpoch 4/15\n\u001b[1m166/166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 734ms/step - loss: 0.3698 - sparse_categorical_accuracy: 0.6185\nEpoch 5/15\n\u001b[1m166/166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 734ms/step - loss: 0.3357 - sparse_categorical_accuracy: 0.6457\nEpoch 6/15\n\u001b[1m166/166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 733ms/step - loss: 0.2926 - sparse_categorical_accuracy: 0.6853\nEpoch 7/15\n\u001b[1m166/166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 860ms/step - loss: 0.2471 - sparse_categorical_accuracy: 0.7297\nEpoch 8/15\n\u001b[1m166/166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 733ms/step - loss: 0.2091 - sparse_categorical_accuracy: 0.7702\nEpoch 9/15\n\u001b[1m166/166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 733ms/step - loss: 0.1753 - sparse_categorical_accuracy: 0.8055\nEpoch 10/15\n\u001b[1m166/166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 734ms/step - loss: 0.1513 - sparse_categorical_accuracy: 0.8330\nEpoch 11/15\n\u001b[1m166/166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 733ms/step - loss: 0.1306 - sparse_categorical_accuracy: 0.8560\nEpoch 12/15\n\u001b[1m166/166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 733ms/step - loss: 0.1139 - sparse_categorical_accuracy: 0.8771\nEpoch 13/15\n\u001b[1m166/166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 733ms/step - loss: 0.0966 - sparse_categorical_accuracy: 0.8948\nEpoch 14/15\n\u001b[1m166/166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 733ms/step - loss: 0.0767 - sparse_categorical_accuracy: 0.9188\nEpoch 15/15\n\u001b[1m166/166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 734ms/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9281\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7ec5b064ff70>"},"metadata":{}}]},{"cell_type":"code","source":"gemma_lm.save('version_finetunded_ds.keras')","metadata":{"execution":{"iopub.status.busy":"2024-03-01T04:10:35.900701Z","iopub.execute_input":"2024-03-01T04:10:35.901147Z","iopub.status.idle":"2024-03-01T04:11:41.969716Z","shell.execute_reply.started":"2024-03-01T04:10:35.901109Z","shell.execute_reply":"2024-03-01T04:11:41.968796Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(gemma_lm.generate(\"What is a Confusion Matrix\", max_length=256))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T04:14:37.874123Z","iopub.execute_input":"2024-03-01T04:14:37.874870Z","iopub.status.idle":"2024-03-01T04:14:45.091156Z","shell.execute_reply.started":"2024-03-01T04:14:37.874840Z","shell.execute_reply":"2024-03-01T04:14:45.090049Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"What is a Confusion Matrix? What does it represent?\n\nA confusion matrix is a table that summarizes the predictions of a model and the ground truth labels.\n\nIt consists of three columns: True Positives (TP), True Negative (TN), and False Positive (FP).\n\n* TP is the number of true positives, which is when the model predicts a positive result and the ground truth is also positive.\n* TN is the number of true negatives, which is when the model predicts a negative result and the ground truth is also negative.\n* FP is the number of false positives, which is when the model predicts a positive result and the ground truth is also negative, or equivalently, when a negative result is predicted.\n* Model accuracy = TN + TP / (TP + FP)\n* Precision = TP / (TP + FP)\n* Recall = TN / (TP + TN)\n\nModel accuracy is a bit misleading because it doesn't tell you anything about the model's performance on negative examples. Precision and recall are ways of measuring how well a model is distinguishing between positive and negative examples.\n\nA confusion matrix can help you see how well your model is performing on different types of examples (e.g., false positives and false negatives\n","output_type":"stream"}]},{"cell_type":"code","source":"print(gemma_lm.generate(\"What is the significance of p-value?\", max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T04:22:43.587795Z","iopub.execute_input":"2024-03-01T04:22:43.588603Z","iopub.status.idle":"2024-03-01T04:22:45.032899Z","shell.execute_reply.started":"2024-03-01T04:22:43.588573Z","shell.execute_reply":"2024-03-01T04:22:45.031834Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"What is the significance of p-value?\n\nAnswer:\n\nThe p-value is a measure of the significance of a given result. It tells you how likely it is that the result could be random or unimportant, and thus how significant it actually is.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(gemma_lm.generate(\"what is bias in data science\", max_length = 256))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T04:24:18.960831Z","iopub.execute_input":"2024-03-01T04:24:18.961214Z","iopub.status.idle":"2024-03-01T04:24:20.241133Z","shell.execute_reply.started":"2024-03-01T04:24:18.961183Z","shell.execute_reply":"2024-03-01T04:24:20.239830Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"what is bias in data science? how it affects our models?\n\nAnswer:\n\nBias in data science is an error introduced by the model itself. It affects the model's ability to generalize and make accurate predictions.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Let's try this - now move on to finetuning the model to write Python code","metadata":{}},{"cell_type":"markdown","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-02-29T23:37:50.487075Z","iopub.execute_input":"2024-02-29T23:37:50.488032Z","iopub.status.idle":"2024-02-29T23:37:50.502669Z","shell.execute_reply.started":"2024-02-29T23:37:50.487998Z","shell.execute_reply":"2024-02-29T23:37:50.501747Z"}}},{"cell_type":"code","source":"file = pd.read_parquet(\"/kaggle/input/parquetfile-python-25k/0000.parquet\")","metadata":{"execution":{"iopub.status.busy":"2024-03-01T04:24:28.975512Z","iopub.execute_input":"2024-03-01T04:24:28.975886Z","iopub.status.idle":"2024-03-01T04:24:30.101104Z","shell.execute_reply.started":"2024-03-01T04:24:28.975857Z","shell.execute_reply":"2024-03-01T04:24:30.100230Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"data=file.apply(lambda row:f\"Instruction:\\n{row.instruction}\\n\\nResponse:\\n{row.output}\",axis=1).values.tolist()[:1000]","metadata":{"execution":{"iopub.status.busy":"2024-03-01T04:24:32.508282Z","iopub.execute_input":"2024-03-01T04:24:32.508685Z","iopub.status.idle":"2024-03-01T04:24:33.795114Z","shell.execute_reply.started":"2024-03-01T04:24:32.508657Z","shell.execute_reply":"2024-03-01T04:24:33.794246Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(data[1])","metadata":{"execution":{"iopub.status.busy":"2024-03-01T04:24:37.721423Z","iopub.execute_input":"2024-03-01T04:24:37.721786Z","iopub.status.idle":"2024-03-01T04:24:37.726989Z","shell.execute_reply.started":"2024-03-01T04:24:37.721760Z","shell.execute_reply":"2024-03-01T04:24:37.725926Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Instruction:\nCreate a shopping list based on my inputs!\n\nResponse:\n```python\nshopping_list = {}\nwhile True:\n    item = input('Enter an item or type 'done' to finish: ')\n    if item == 'done': break\n    quantity = input(f'Enter the quantity for {item}: ')\n    shopping_list[item] = quantity\nprint(f'Your shopping list: {shopping_list}')\n```\n","output_type":"stream"}]},{"cell_type":"code","source":"gemma_lm.preprocessor.sequence_length = 128\n\noptimizer = keras.optimizers.AdamW(\n    learning_rate=5e-6,\n    weight_decay=0.01,\n)\n\noptimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\ngemma_lm.fit(data, epochs=1, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T04:24:45.372787Z","iopub.execute_input":"2024-03-01T04:24:45.373201Z","iopub.status.idle":"2024-03-01T04:28:55.505045Z","shell.execute_reply.started":"2024-03-01T04:24:45.373172Z","shell.execute_reply":"2024-03-01T04:28:55.504001Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 227ms/step - loss: 1.0463 - sparse_categorical_accuracy: 0.6993\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7ec57c250490>"},"metadata":{}}]},{"cell_type":"code","source":"gemma_lm.save(\"version_finetuned_code.keras\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T04:29:18.702787Z","iopub.execute_input":"2024-03-01T04:29:18.703552Z","iopub.status.idle":"2024-03-01T04:30:23.848126Z","shell.execute_reply.started":"2024-03-01T04:29:18.703520Z","shell.execute_reply":"2024-03-01T04:30:23.846952Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"instruction=\"write a code for creating a list in python\"\nresponse=\"\"\nprompt = f\"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\nprint(gemma_lm.generate(prompt, max_length=128))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T04:30:33.264375Z","iopub.execute_input":"2024-03-01T04:30:33.265353Z","iopub.status.idle":"2024-03-01T04:30:33.935014Z","shell.execute_reply.started":"2024-03-01T04:30:33.265313Z","shell.execute_reply":"2024-03-01T04:30:33.934031Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Instruction:\nwrite a code for creating a list in python\n\nResponse:\n```python\nimport numpy as np\nlst = np.array([])\n```\n","output_type":"stream"}]}]}